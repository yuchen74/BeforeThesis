{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "offshore-reviewer",
   "metadata": {},
   "source": [
    "# Dataset: *gurlitt*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-chick",
   "metadata": {},
   "source": [
    "- df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\gurlitt-df.csv',index=False)\n",
    "- src_tw_df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\gurlitt-src.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cleared-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "combined-tissue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifty-memphis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 11)\n",
      "(138, 7)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\gurlitt-df.csv', encoding = 'utf-8', header = 0)\n",
    "src_tw_df = pd.read_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\gurlitt-src.csv', encoding = 'utf-8', header =0)\n",
    "print(df.shape)\n",
    "print(src_tw_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "devoted-garage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reply_tweet             NaN\n",
       "cleaned_reply_tw        NaN\n",
       "reply_sentiment     Neutral\n",
       "Name: 23, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[23,['reply_tweet','cleaned_reply_tw','reply_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "posted-forest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reply_tweet             NaN\n",
       "cleaned_reply_tw        NaN\n",
       "reply_sentiment     Neutral\n",
       "Name: 48, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[48,['reply_tweet','cleaned_reply_tw','reply_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incident-treatment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src_tweet_id          0\n",
       "src_user_id           0\n",
       "src_tweet             0\n",
       "src_date              0\n",
       "reply_tweet_id      123\n",
       "reply_user_id       123\n",
       "reply_tweet         123\n",
       "reply_date          123\n",
       "label                 0\n",
       "cleaned_reply_tw    125\n",
       "reply_sentiment       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "victorian-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affected-karen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src_tweet_id      0\n",
       "src_user_id       0\n",
       "src_tweet         0\n",
       "src_date          0\n",
       "label             0\n",
       "cleaned_src_tw    0\n",
       "src_sentiment     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tw_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-remedy",
   "metadata": {},
   "source": [
    "## Emotion Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-treat",
   "metadata": {},
   "source": [
    "### roBERTa-base model\n",
    "<https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intended-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "task='emotion'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "ro_tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "ro_model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lucky-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_roBERT(text):\n",
    "    \n",
    "    def preprocess(txt):\n",
    "        new_text = []\n",
    "        for t in txt.split(\" \"):\n",
    "            t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "            t = 'http' if t.startswith('http') else t\n",
    "            new_text.append(t)\n",
    "        return \" \".join(new_text)\n",
    "    \n",
    "    labels = ['anger','joy','optimism','sadness']\n",
    "    text = preprocess(text)\n",
    "    encoded_input = ro_tokenizer(text, return_tensors='pt')\n",
    "    output = ro_model(**encoded_input)\n",
    "\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    emo = labels[ranking[0]]\n",
    "    return emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "logical-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_ro = df.cleaned_reply_tw.astype(str).apply(get_emotion_roBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acoustic-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reply_emo_ro'] = emotion_ro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "transparent-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\gurlitt-df-2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "apart-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_emo_ro = src_tw_df.cleaned_src_tw.astype(str).apply(get_emotion_roBERT)\n",
    "src_tw_df['src_emo_ro'] = src_emo_ro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boolean-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tw_df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\gurlitt-src-2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-effort",
   "metadata": {},
   "source": [
    " - robert : 'anger','joy','optimism','sadness'\n",
    " - t5: 'sadness', 'joy', 'love', 'anger', 'fear', 'surprise' \n",
    " - text2emotion: 'angry, 'fear', 'happy, 'sad', 'surprise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "applied-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source tweet: ‘The Gurlitt collection should be sold to benefit Jewish organisations’ - The Art Newspaper http://t.co/DZLCSAoGIp \n",
      "\n",
      "original reply tw:  nan\n",
      "cleaned reply tw:  nan\n",
      "roBerta:  joy\n"
     ]
    }
   ],
   "source": [
    "print(\"source tweet:\", df.src_tweet[18],'\\n')\n",
    "print(\"original reply tw: \", df.reply_tweet[18])\n",
    "print(\"cleaned reply tw: \", df.cleaned_reply_tw[18])\n",
    "\n",
    "print('roBerta: ', df.reply_emo_ro[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-protein",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
