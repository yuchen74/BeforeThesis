{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "reasonable-tractor",
   "metadata": {},
   "source": [
    "# Text Analysis on ottawashooting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "planned-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "voluntary-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\ottawashooting.csv', encoding = 'utf-8', header = None)\n",
    "df.columns = ['src_tweet_id', 'src_user_id', 'src_tweet','src_date','reply_tweet_id','reply_user_id','reply_tweet','reply_date', 'label']\n",
    "df.reply_tweet = df.reply_tweet.replace(np.nan,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "verified-violin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['src_tweet_id', 'src_user_id', 'src_tweet', 'src_date',\n",
       "       'reply_tweet_id', 'reply_user_id', 'reply_tweet', 'reply_date',\n",
       "       'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "statewide-vertical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tweet_id</th>\n",
       "      <th>src_user_id</th>\n",
       "      <th>src_tweet</th>\n",
       "      <th>src_date</th>\n",
       "      <th>reply_tweet_id</th>\n",
       "      <th>reply_user_id</th>\n",
       "      <th>reply_tweet</th>\n",
       "      <th>reply_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>524922078638903296</td>\n",
       "      <td>18999969</td>\n",
       "      <td>Ottawa police are confirming a shooting at the...</td>\n",
       "      <td>Wed Oct 22 13:55:50 +0000 2014</td>\n",
       "      <td>524922392582586368</td>\n",
       "      <td>2433907530</td>\n",
       "      <td>.@dominiquehardy @CBCOttawa related to St-Jean ?</td>\n",
       "      <td>Wed Oct 22 13:57:05 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>524922078638903296</td>\n",
       "      <td>18999969</td>\n",
       "      <td>Ottawa police are confirming a shooting at the...</td>\n",
       "      <td>Wed Oct 22 13:55:50 +0000 2014</td>\n",
       "      <td>524922589861658624</td>\n",
       "      <td>15816550</td>\n",
       "      <td>@petitmetroide @CBCOttawa Il est tôt pour une ...</td>\n",
       "      <td>Wed Oct 22 13:57:52 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>524922078638903296</td>\n",
       "      <td>18999969</td>\n",
       "      <td>Ottawa police are confirming a shooting at the...</td>\n",
       "      <td>Wed Oct 22 13:55:50 +0000 2014</td>\n",
       "      <td>524922681595269120</td>\n",
       "      <td>1206639234</td>\n",
       "      <td>Prudence avant d'en savoir plus “@CBCOttawa: O...</td>\n",
       "      <td>Wed Oct 22 13:58:14 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524922078638903296</td>\n",
       "      <td>18999969</td>\n",
       "      <td>Ottawa police are confirming a shooting at the...</td>\n",
       "      <td>Wed Oct 22 13:55:50 +0000 2014</td>\n",
       "      <td>524923071090917376</td>\n",
       "      <td>347531577</td>\n",
       "      <td>@StephBerthomet Ça va être rapporté partout sa...</td>\n",
       "      <td>Wed Oct 22 13:59:47 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>524922078638903296</td>\n",
       "      <td>18999969</td>\n",
       "      <td>Ottawa police are confirming a shooting at the...</td>\n",
       "      <td>Wed Oct 22 13:55:50 +0000 2014</td>\n",
       "      <td>524923096911052802</td>\n",
       "      <td>96146974</td>\n",
       "      <td>“@CBCOttawa: Ottawa police are confirming a sh...</td>\n",
       "      <td>Wed Oct 22 13:59:53 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>525072912957452289</td>\n",
       "      <td>19636948</td>\n",
       "      <td>This photo, reported to be of suspected Ottawa...</td>\n",
       "      <td>Wed Oct 22 23:55:12 +0000 2014</td>\n",
       "      <td>525100575852343297</td>\n",
       "      <td>930938779</td>\n",
       "      <td>@TdotBrownMon @Mairsy27 that soldier had nothi...</td>\n",
       "      <td>Thu Oct 23 01:45:07 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11390</th>\n",
       "      <td>525072912957452289</td>\n",
       "      <td>19636948</td>\n",
       "      <td>This photo, reported to be of suspected Ottawa...</td>\n",
       "      <td>Wed Oct 22 23:55:12 +0000 2014</td>\n",
       "      <td>525100743146352640</td>\n",
       "      <td>100150714</td>\n",
       "      <td>@thejangler6 @Mairsy27 exactly is not the pers...</td>\n",
       "      <td>Thu Oct 23 01:45:47 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11391</th>\n",
       "      <td>525072912957452289</td>\n",
       "      <td>19636948</td>\n",
       "      <td>This photo, reported to be of suspected Ottawa...</td>\n",
       "      <td>Wed Oct 22 23:55:12 +0000 2014</td>\n",
       "      <td>525102255515922432</td>\n",
       "      <td>322148870</td>\n",
       "      <td>@allstaradele @CP24 what a hero! Gave his life...</td>\n",
       "      <td>Thu Oct 23 01:51:48 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11392</th>\n",
       "      <td>525072912957452289</td>\n",
       "      <td>19636948</td>\n",
       "      <td>This photo, reported to be of suspected Ottawa...</td>\n",
       "      <td>Wed Oct 22 23:55:12 +0000 2014</td>\n",
       "      <td>525102464773931008</td>\n",
       "      <td>100150714</td>\n",
       "      <td>@Mairsy27 @thejangler6 wrd but i kno wagwanin ...</td>\n",
       "      <td>Thu Oct 23 01:52:38 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11393</th>\n",
       "      <td>525072912957452289</td>\n",
       "      <td>19636948</td>\n",
       "      <td>This photo, reported to be of suspected Ottawa...</td>\n",
       "      <td>Wed Oct 22 23:55:12 +0000 2014</td>\n",
       "      <td>525140450731372544</td>\n",
       "      <td>404610392</td>\n",
       "      <td>@JFerraraF18 @ruthia911 @beets79 @CP24 I agree...</td>\n",
       "      <td>Thu Oct 23 04:23:34 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11394 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             src_tweet_id  src_user_id  \\\n",
       "0      524922078638903296     18999969   \n",
       "1      524922078638903296     18999969   \n",
       "2      524922078638903296     18999969   \n",
       "3      524922078638903296     18999969   \n",
       "4      524922078638903296     18999969   \n",
       "...                   ...          ...   \n",
       "11389  525072912957452289     19636948   \n",
       "11390  525072912957452289     19636948   \n",
       "11391  525072912957452289     19636948   \n",
       "11392  525072912957452289     19636948   \n",
       "11393  525072912957452289     19636948   \n",
       "\n",
       "                                               src_tweet  \\\n",
       "0      Ottawa police are confirming a shooting at the...   \n",
       "1      Ottawa police are confirming a shooting at the...   \n",
       "2      Ottawa police are confirming a shooting at the...   \n",
       "3      Ottawa police are confirming a shooting at the...   \n",
       "4      Ottawa police are confirming a shooting at the...   \n",
       "...                                                  ...   \n",
       "11389  This photo, reported to be of suspected Ottawa...   \n",
       "11390  This photo, reported to be of suspected Ottawa...   \n",
       "11391  This photo, reported to be of suspected Ottawa...   \n",
       "11392  This photo, reported to be of suspected Ottawa...   \n",
       "11393  This photo, reported to be of suspected Ottawa...   \n",
       "\n",
       "                             src_date      reply_tweet_id  reply_user_id  \\\n",
       "0      Wed Oct 22 13:55:50 +0000 2014  524922392582586368     2433907530   \n",
       "1      Wed Oct 22 13:55:50 +0000 2014  524922589861658624       15816550   \n",
       "2      Wed Oct 22 13:55:50 +0000 2014  524922681595269120     1206639234   \n",
       "3      Wed Oct 22 13:55:50 +0000 2014  524923071090917376      347531577   \n",
       "4      Wed Oct 22 13:55:50 +0000 2014  524923096911052802       96146974   \n",
       "...                               ...                 ...            ...   \n",
       "11389  Wed Oct 22 23:55:12 +0000 2014  525100575852343297      930938779   \n",
       "11390  Wed Oct 22 23:55:12 +0000 2014  525100743146352640      100150714   \n",
       "11391  Wed Oct 22 23:55:12 +0000 2014  525102255515922432      322148870   \n",
       "11392  Wed Oct 22 23:55:12 +0000 2014  525102464773931008      100150714   \n",
       "11393  Wed Oct 22 23:55:12 +0000 2014  525140450731372544      404610392   \n",
       "\n",
       "                                             reply_tweet  \\\n",
       "0       .@dominiquehardy @CBCOttawa related to St-Jean ?   \n",
       "1      @petitmetroide @CBCOttawa Il est tôt pour une ...   \n",
       "2      Prudence avant d'en savoir plus “@CBCOttawa: O...   \n",
       "3      @StephBerthomet Ça va être rapporté partout sa...   \n",
       "4      “@CBCOttawa: Ottawa police are confirming a sh...   \n",
       "...                                                  ...   \n",
       "11389  @TdotBrownMon @Mairsy27 that soldier had nothi...   \n",
       "11390  @thejangler6 @Mairsy27 exactly is not the pers...   \n",
       "11391  @allstaradele @CP24 what a hero! Gave his life...   \n",
       "11392  @Mairsy27 @thejangler6 wrd but i kno wagwanin ...   \n",
       "11393  @JFerraraF18 @ruthia911 @beets79 @CP24 I agree...   \n",
       "\n",
       "                           reply_date  label  \n",
       "0      Wed Oct 22 13:57:05 +0000 2014      0  \n",
       "1      Wed Oct 22 13:57:52 +0000 2014      0  \n",
       "2      Wed Oct 22 13:58:14 +0000 2014      0  \n",
       "3      Wed Oct 22 13:59:47 +0000 2014      0  \n",
       "4      Wed Oct 22 13:59:53 +0000 2014      0  \n",
       "...                               ...    ...  \n",
       "11389  Thu Oct 23 01:45:07 +0000 2014      1  \n",
       "11390  Thu Oct 23 01:45:47 +0000 2014      1  \n",
       "11391  Thu Oct 23 01:51:48 +0000 2014      1  \n",
       "11392  Thu Oct 23 01:52:38 +0000 2014      1  \n",
       "11393  Thu Oct 23 04:23:34 +0000 2014      1  \n",
       "\n",
       "[11394 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-scott",
   "metadata": {},
   "source": [
    "## Prepocessing\n",
    "- Define function to process text at one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sexual-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "educational-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Convert Emojis to Words'''\n",
    "\n",
    "with open(r'D:\\論文\\PHEME9\\Emoji_Dict.p', 'rb') as fp:\n",
    "    Emoji_Dict = pickle.load(fp)\n",
    "Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "\n",
    "def convert_emojis_to_word(text):\n",
    "    import re\n",
    "    for emot in Emoji_Dict:\n",
    "        text = re.sub(r'('+emot+')', \"_\".join(Emoji_Dict[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "varying-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textprocessing(text):\n",
    "    \n",
    "    text = text.lower()           #lower case\n",
    "    \n",
    "    if 'rt' in text.split():      #cut retweet\n",
    "        rt = text.find('RT')\n",
    "        text = text[0:rt]  \n",
    "        \n",
    "    quo = text.find('“')           #cut quoting part\n",
    "    quo_end = text.find('”')\n",
    "    at = text.find('@')\n",
    "    if quo != -1:                  #if find “\n",
    "        if quo_end != -1:             # and if there is also ”\n",
    "            text = text[0: quo:] + text[quo_end+1: :]\n",
    "        else:\n",
    "            text = text[0: quo:]\n",
    "    elif quo_end != -1:\n",
    "        text = text[0:at:] + text[quo_end+1: : ]\n",
    "            \n",
    "   \n",
    "    text = convert_emojis_to_word(text)   #convert emoji to word\n",
    "        \n",
    "     \n",
    "    \n",
    "    text = \" \".join([word for word in text.split() if 'http' not in word    #remove url\n",
    "                                and not word.startswith(('\\'@','@'))\n",
    "                                and word != 'rt'])   \n",
    "                 \n",
    "    import re\n",
    "    def remove_punct(tweet):\n",
    "        new_words = []\n",
    "        for word in tweet:\n",
    "            w = re.sub(r'[^\\w\\s]','',word) #remove everything except words and space\n",
    "            w = re.sub(r'_','',w) #remove underscore as well\n",
    "            new_words.append(w)\n",
    "\n",
    "        return new_words\n",
    "    text = \"\".join(remove_punct(text))\n",
    "\n",
    "    from nltk.tokenize import word_tokenize   \n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    stop_words=set([a for a in list(stop_words) if re.search(\"n't|no|not\",a) ==None])\n",
    "    stop_words.add('now')\n",
    "    def filterstopwords(tw):\n",
    "        filter_stopwords = []\n",
    "        for w in tw:\n",
    "            if w not in stop_words:\n",
    "                filter_stopwords.append(w)\n",
    "        return filter_stopwords\n",
    "    text = filterstopwords(text)\n",
    "    \n",
    "    \n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    \n",
    "#     from nltk.stem.porter import PorterStemmer\n",
    "#     stem = PorterStemmer()\n",
    "#     text = [stem.stem(i) for i in text]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "purple-arbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source tweet:  Ottawa police are confirming a shooting at the War Memorial. Minutes ago. No other info. #cbcOTT #OTTnews\n",
      "original text:  “@disneywords: I'm like a shooting star, I've come so far. I can't go back to where I used to be. –Jasmine (Aladdin)” @marreebear7\n",
      "cleaned text:  \n"
     ]
    }
   ],
   "source": [
    "print(\"source tweet: \", df.src_tweet.iloc[15])\n",
    "print(\"original text: \", df.reply_tweet.iloc[1678])\n",
    "print(\"cleaned text: \", textprocessing(df.reply_tweet.iloc[1678]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "loaded-juvenile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotweet = df[df.reply_tweet.str.find('“') != -1].index\n",
    "quo_tweet = df[df.reply_tweet.str.find('”') != -1].index\n",
    "rtt = df[df.reply_tweet.str.find('RT') != -1].index\n",
    "at =  df[df.reply_tweet.str.find('@') != -1].index\n",
    "\n",
    "set(quo_tweet).difference(set(rtt)).difference(set(quotweet)).difference(set(at))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-dining",
   "metadata": {},
   "source": [
    "### applied on original data (**df**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_src_tw'] = df.src_tweet.apply(textprocessing)\n",
    "df['cleaned_reply_tw'] = df.reply_tweet.apply(textprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-difference",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tweet):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    if vs['compound'] >=0.05:\n",
    "        sentiment_label = 'Positive'\n",
    "    elif (vs['compound'] > -0.05) & (vs['compound'] < 0.05):\n",
    "        sentiment_label = 'Neutral'\n",
    "    elif vs['compound']<= -0.05:\n",
    "        sentiment_label = 'Negative' \n",
    "    result = sentiment_label\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-wholesale",
   "metadata": {},
   "source": [
    "### applied on original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['src_sentiment']= df.cleaned_src_tw.apply(get_sentiment)\n",
    "df['reply_sentiment']= df.cleaned_reply_tw.apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-equivalent",
   "metadata": {},
   "source": [
    "### Source tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tw_df = df.iloc[:,[0,1,2,3,8,9,11]].copy()\n",
    "src_tw_df = src_tw_df.drop_duplicates()\n",
    "src_tw_df.reset_index(drop=True,inplace=True)\n",
    "src_tw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-deposit",
   "metadata": {},
   "source": [
    "### save data to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\ottawashooting-df.csv',index=False)\n",
    "src_tw_df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\ottawashooting-src.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-salad",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Keywords Extraction\n",
    "### WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(docx)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-afghanistan",
   "metadata": {},
   "source": [
    "#### Reply Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_sen = df.cleaned_reply_tw.apply(word_tokenize)\n",
    "reply_tw_list = []\n",
    "for sen in reply_sen:\n",
    "    for token in sen:\n",
    "        reply_tw_list.append(token)\n",
    "reply_tw_doc = \" \".join(reply_tw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(reply_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/ottawashooting/wordcloud_reply.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive \n",
    "posi_reply_sen = df[df.reply_sentiment=='Positive'].cleaned_reply_tw.apply(word_tokenize)\n",
    "posi_reply_tw_list = []\n",
    "for sen in posi_reply_sen:\n",
    "    for token in sen:\n",
    "        posi_reply_tw_list.append(token)\n",
    "posi_reply_tw_doc = \" \".join(posi_reply_tw_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(posi_reply_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/ottawashooting/wordcloud_reply_posi.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-floating",
   "metadata": {},
   "source": [
    "#### Source Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sen = src_tw_df.cleaned_src_tw.apply(word_tokenize)\n",
    "src_tw_list = []\n",
    "for sen in src_sen:\n",
    "    for token in sen:\n",
    "        src_tw_list.append(token)\n",
    "\n",
    "src_tw_doc = \" \".join(src_tw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(src_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/ottawashooting/wordcloud_src.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-characteristic",
   "metadata": {},
   "source": [
    "### Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "freq = FreqDist(processed_text)\n",
    "freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(docx,num=30):\n",
    "    word_tokens = Counter(docx)\n",
    "    most_common = word_tokens.most_common(num)\n",
    "    result = dict(most_common)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_tokens(reply_tw_list).items(),columns=['word','freq']).plot(kind='bar',x='word',y='freq')\n",
    "plt.title(\"Most frequent words among reply tweets are 'Prince','show','tonight'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_tokens(src_tw_list).items(),columns=['word','freq']).plot(kind='bar',x='word',y='freq')\n",
    "plt.title(\"Most frequent words among source tweets are 'Price', 'show', 'tonight'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-jordan",
   "metadata": {},
   "source": [
    "## Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-vermont",
   "metadata": {},
   "source": [
    "### text2emotion package\n",
    "https://snyk.io/advisor/python/text2emotion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import text2emotion as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = df.cleaned_reply_tw.apply(te.get_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo = emotion.apply(lambda x: max(x,key=x.get))\n",
    "df['reply_emo_te'] = emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\ottawashooting-df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion1 = src_tw_df.cleaned_src_tw.apply(te.get_emotion)\n",
    "emo1 = emotion.apply(lambda x: max(x,key=x.get))\n",
    "src_tw_df['src_emo_te']=emo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tw_df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\ottawashooting-src.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-colony",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
