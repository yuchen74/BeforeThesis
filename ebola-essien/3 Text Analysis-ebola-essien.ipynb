{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "noticed-spectrum",
   "metadata": {},
   "source": [
    "# Text Analysis on ebola-essien data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nervous-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "played-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\ebola-essien.csv', encoding = 'utf-8', header = None)\n",
    "df.columns = ['src_tweet_id', 'src_user_id', 'src_tweet','src_date','reply_tweet_id','reply_user_id','reply_tweet','reply_date', 'label']\n",
    "df.reply_tweet = df.reply_tweet.replace(np.nan,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "racial-harrison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tweet_id</th>\n",
       "      <th>src_user_id</th>\n",
       "      <th>src_tweet</th>\n",
       "      <th>src_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>521310417696858112</td>\n",
       "      <td>964926744</td>\n",
       "      <td>Breaking news: Ghana international and AC Mila...</td>\n",
       "      <td>Sun Oct 12 14:44:23 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>521346721226711040</td>\n",
       "      <td>579635019</td>\n",
       "      <td>Unconfirmed reports claim that Michael Essien ...</td>\n",
       "      <td>Sun Oct 12 17:08:39 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>521350916872876033</td>\n",
       "      <td>2449736654</td>\n",
       "      <td>BREAKING: Unconfirmed reports claim AC Milan m...</td>\n",
       "      <td>Sun Oct 12 17:25:19 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>521358118597689344</td>\n",
       "      <td>24044553</td>\n",
       "      <td>Milan have stated that the reports about Essie...</td>\n",
       "      <td>Sun Oct 12 17:53:56 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>521359454672269313</td>\n",
       "      <td>2330299633</td>\n",
       "      <td>AC Milan midfielder Michael Essien has been di...</td>\n",
       "      <td>Sun Oct 12 17:59:15 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>521359863884967936</td>\n",
       "      <td>315113964</td>\n",
       "      <td>Milan release official statement on their site...</td>\n",
       "      <td>Sun Oct 12 18:00:52 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>521360486387175424</td>\n",
       "      <td>1594903015</td>\n",
       "      <td>AC Milan midfielder Michael Essien has been di...</td>\n",
       "      <td>Sun Oct 12 18:03:21 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>521361857810939905</td>\n",
       "      <td>1742526258</td>\n",
       "      <td>AC Milan have confirmed that the reports about...</td>\n",
       "      <td>Sun Oct 12 18:08:47 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>521367917322338304</td>\n",
       "      <td>1262229906</td>\n",
       "      <td>No truth in internet rumours that I have contr...</td>\n",
       "      <td>Sun Oct 12 18:32:52 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>521369179392581632</td>\n",
       "      <td>159412087</td>\n",
       "      <td>Micheal Essien denying the Ebola rumours like ...</td>\n",
       "      <td>Sun Oct 12 18:37:53 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>521375609206083584</td>\n",
       "      <td>1561123663</td>\n",
       "      <td>Good news: The rumours that Michael Essien has...</td>\n",
       "      <td>Sun Oct 12 19:03:26 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>521381662551474176</td>\n",
       "      <td>1262229906</td>\n",
       "      <td>I'm very fit and very healthy,No truth in the ...</td>\n",
       "      <td>Sun Oct 12 19:27:29 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>521595221155774464</td>\n",
       "      <td>301413580</td>\n",
       "      <td>AC Milan have denied reports that midfielder M...</td>\n",
       "      <td>Mon Oct 13 09:36:06 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>522286703848218624</td>\n",
       "      <td>24044553</td>\n",
       "      <td>Essien and his lawyers are considering to file...</td>\n",
       "      <td>Wed Oct 15 07:23:48 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           src_tweet_id  src_user_id  \\\n",
       "0    521310417696858112    964926744   \n",
       "26   521346721226711040    579635019   \n",
       "52   521350916872876033   2449736654   \n",
       "70   521358118597689344     24044553   \n",
       "74   521359454672269313   2330299633   \n",
       "98   521359863884967936    315113964   \n",
       "107  521360486387175424   1594903015   \n",
       "115  521361857810939905   1742526258   \n",
       "128  521367917322338304   1262229906   \n",
       "146  521369179392581632    159412087   \n",
       "160  521375609206083584   1561123663   \n",
       "172  521381662551474176   1262229906   \n",
       "191  521595221155774464    301413580   \n",
       "206  522286703848218624     24044553   \n",
       "\n",
       "                                             src_tweet  \\\n",
       "0    Breaking news: Ghana international and AC Mila...   \n",
       "26   Unconfirmed reports claim that Michael Essien ...   \n",
       "52   BREAKING: Unconfirmed reports claim AC Milan m...   \n",
       "70   Milan have stated that the reports about Essie...   \n",
       "74   AC Milan midfielder Michael Essien has been di...   \n",
       "98   Milan release official statement on their site...   \n",
       "107  AC Milan midfielder Michael Essien has been di...   \n",
       "115  AC Milan have confirmed that the reports about...   \n",
       "128  No truth in internet rumours that I have contr...   \n",
       "146  Micheal Essien denying the Ebola rumours like ...   \n",
       "160  Good news: The rumours that Michael Essien has...   \n",
       "172  I'm very fit and very healthy,No truth in the ...   \n",
       "191  AC Milan have denied reports that midfielder M...   \n",
       "206  Essien and his lawyers are considering to file...   \n",
       "\n",
       "                           src_date  label  \n",
       "0    Sun Oct 12 14:44:23 +0000 2014      1  \n",
       "26   Sun Oct 12 17:08:39 +0000 2014      1  \n",
       "52   Sun Oct 12 17:25:19 +0000 2014      1  \n",
       "70   Sun Oct 12 17:53:56 +0000 2014      1  \n",
       "74   Sun Oct 12 17:59:15 +0000 2014      1  \n",
       "98   Sun Oct 12 18:00:52 +0000 2014      1  \n",
       "107  Sun Oct 12 18:03:21 +0000 2014      1  \n",
       "115  Sun Oct 12 18:08:47 +0000 2014      1  \n",
       "128  Sun Oct 12 18:32:52 +0000 2014      1  \n",
       "146  Sun Oct 12 18:37:53 +0000 2014      1  \n",
       "160  Sun Oct 12 19:03:26 +0000 2014      1  \n",
       "172  Sun Oct 12 19:27:29 +0000 2014      1  \n",
       "191  Mon Oct 13 09:36:06 +0000 2014      1  \n",
       "206  Wed Oct 15 07:23:48 +0000 2014      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tw_df = df.iloc[:,[0,1,2,3,8]].copy()\n",
    "src_tw_df = src_tw_df.drop_duplicates()\n",
    "src_tw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-cardiff",
   "metadata": {},
   "source": [
    "## Prepocessing\n",
    "- Define function to process text at one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adaptive-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textprocessing(text):\n",
    "     \n",
    "    text = text.lower()\n",
    "\n",
    "    quo = text.find('“')\n",
    "    quo_end = text.find('”')\n",
    "    if quo != -1:\n",
    "        if quo_end != -1:\n",
    "            text = text[0: quo:] + text[quo_end+1: :]\n",
    "        else:\n",
    "            quo_end2 = text.find('“',quo+1)\n",
    "            text = text[0: quo:] + text[quo_end2+1: :]\n",
    "\n",
    "    text = \" \".join([word for word in text.split() if ('http' not in word)\\\n",
    "                                and (word.startswith('@')==False) \\\n",
    "                                and word != 'rt'])\n",
    "    import re\n",
    "    def remove_punct(tweet):\n",
    "        new_words = []\n",
    "        for word in tweet:\n",
    "            w = re.sub(r'[^\\w\\s]','',word) #remove everything except words and space\n",
    "            w = re.sub(r'_','',w) #how to remove underscore as well\n",
    "            new_words.append(w)\n",
    "\n",
    "        return new_words\n",
    "    text = \"\".join(remove_punct(text))\n",
    "          \n",
    "    from nltk.tokenize import TweetTokenizer\n",
    "    tknzr = TweetTokenizer(strip_handles=True)\n",
    "    text = tknzr.tokenize(text)\n",
    "    \n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stem = PorterStemmer()\n",
    "    text = [stem.stem(i) for i in text]\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    stop_words=set([a for a in list(stop_words) if a.find(\"n't\") ==-1])\n",
    "    def filterstopwords(tw):\n",
    "        filter_stopwords = []\n",
    "        for w in tw:\n",
    "            if w not in stop_words:\n",
    "                filter_stopwords.append(w)\n",
    "        return filter_stopwords\n",
    "    text = filterstopwords(text)\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "addressed-perfume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source tweet:  I'm very fit and very healthy,No truth in the internet rumours that I have contracted Ebola.im well &amp;… http://t.co/TGidyI5JVG \n",
      "\n",
      "original text:  SMH ---&gt; “@MichaelEssien: I'm very fit and very healthy,No truth in the internet rumours that I have contracted Ebola...” \n",
      "\n",
      "cleaned text:  im veri fit veri healthyno truth internet rumour contract ebolaim well amp\n"
     ]
    }
   ],
   "source": [
    "print(\"Source tweet: \", df.src_tweet[176],'\\n')\n",
    "print(\"original text: \", df.reply_tweet.iloc[176],'\\n')\n",
    "print(\"cleaned text: \", textprocessing(df.src_tweet.iloc[176]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "developed-hybrid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      “@YuryAlkaev: Breaking news: Ghana internation...\n",
       "2      “@YuryAlkaev: Breaking news: Ghana internation...\n",
       "3      “@YuryAlkaev: Breaking news: Ghana internation...\n",
       "4      “@YuryAlkaev: Breaking news: Ghana internation...\n",
       "5      “@YuryAlkaev: Breaking news: Ghana internation...\n",
       "6      “@YuryAlkaev: Breaking news: Ghana internation...\n",
       "7      “@YuryAlkaev: Breaking news: Ghana internation...\n",
       "11     what????? “@YuryAlkaev: Breaking news: Ghana i...\n",
       "12     “@YuryAlkaev: Breaking news: Ghana internation...\n",
       "14     “@YuryAlkaev: Breaking news: Ghana internation...\n",
       "16     Huh? “@YuryAlkaev: Breaking news: Ghana intern...\n",
       "17     “@YuryAlkaev: Breaking news: Ghana internation...\n",
       "18     “@YuryAlkaev: Breaking: Ghana international &a...\n",
       "19     RT “@YuryAlkaev: \"he is very strong..the Ebola...\n",
       "20     Wow“@officialAnietie: what????? “@YuryAlkaev: ...\n",
       "27     Stop it! Hope you get Ebola, you utter twat “@...\n",
       "29     “@FootballcomEN: Unconfirmed reports claim tha...\n",
       "30     “@FootballcomEN: Unconfirmed reports claim tha...\n",
       "31     “@FootballcomEN: Unconfirmed reports claim tha...\n",
       "33     “@FootballcomEN: Unconfirmed reports claim tha...\n",
       "34     😯“@FootballcomEN: Unconfirmed reports claim th...\n",
       "36     “@FootballcomEN: Unconfirmed reports claim tha...\n",
       "40     Ok “@FootballcomEN: Unconfirmed reports claim ...\n",
       "47     Yeah it's sad when your family gets it. Idiot....\n",
       "52     “@TheBenchWarming: BREAKING: AC Milan midfield...\n",
       "72     @Mr_Chelsea @Napheu “@Milanello: Milan have st...\n",
       "91     “@TransferRelated: AC Milan midfielder Michael...\n",
       "93     “@TransferRelated: Here is the link to the Mic...\n",
       "104    Disgusting &gt; “@FutbolSergi: @LeahVdc A raci...\n",
       "108    “@FutbolLife: AC Milan midfielder Michael Essi...\n",
       "110    “@FutbolLife: AC Milan midfielder Michael Essi...\n",
       "111    “@FutbolLife: AC Milan midfielder Michael Essi...\n",
       "115    “@Footballltrolls: AC Milan have confirmed tha...\n",
       "118    “@Footballltrolls: AC Milan have confirmed tha...\n",
       "119    “@Footballltrolls: AC Milan have confirmed tha...\n",
       "120    “@Footballltrolls: AC Milan have confirmed tha...\n",
       "122    “@Footballltrolls: AC Milan have confirmed tha...\n",
       "123    “@Footballltrolls: AC Milan have confirmed tha...\n",
       "124    “@Footballltrolls: AC Milan have confirmed tha...\n",
       "126    “@Footballltrolls: AC Milan have confirmed tha...\n",
       "154    “@Mourinholic: Micheal Essien denying the Ebol...\n",
       "155    “@Mourinholic: Micheal Essien denying the Ebol...\n",
       "156    “@Mourinholic: Micheal Essien denying the Ebol...\n",
       "157    “@Mourinholic: Micheal Essien denying the Ebol...\n",
       "166    “@br_uk: Good news: The rumours that Michael E...\n",
       "174    “@MichaelEssien: I'm very fit and very healthy...\n",
       "176    SMH ---&gt; “@MichaelEssien: I'm very fit and ...\n",
       "187    “@MichaelEssien: I'm very fit&amp;very healthy...\n",
       "205    Hehehe RT“@leiboff10: @SuperSportBlitz Essien ...\n",
       "208    “@Milanello: Essien and his lawyers are consid...\n",
       "211    Petty “@Milanello: Essien and his lawyers are ...\n",
       "Name: reply_tweet, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.reply_tweet.str.find('“'or'”') != -1].reply_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-heart",
   "metadata": {},
   "source": [
    "### applied on original data (**df**)reply_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_src_tw'] = df.src_tweet.apply(textprocessing)\n",
    "df['cleaned_reply_tw'] = df.reply_tweet.apply(textprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-description",
   "metadata": {},
   "source": [
    "### applied on source tweet data (**src_tw_df**) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tw_df['cleaned_src_tw'] = src_tw_df.src_tweet.apply(textprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-paste",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tweet):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    if vs['compound'] >=0.05:\n",
    "        sentiment_label = 'Positive'\n",
    "    elif (vs['compound'] > -0.05) & (vs['compound'] < 0.05):\n",
    "        sentiment_label = 'Neutral'\n",
    "    elif vs['compound']<= -0.05:\n",
    "        sentiment_label = 'Negative' \n",
    "    result = sentiment_label\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-settlement",
   "metadata": {},
   "source": [
    "### applied on original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['src_sentiment']= df.cleaned_src_tw.apply(get_sentiment)\n",
    "df['reply_sentiment']= df.cleaned_reply_tw.apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-haven",
   "metadata": {},
   "source": [
    "### applied on source tweet data only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### source tweet data only \n",
    "src_tw_df['src_sentiment']=  src_tw_df['cleaned_src_tw'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-albert",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.label ==1]['reply_sentiment'].value_counts())\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='reply_sentiment',data= df[df['label'] == 1])\n",
    "\n",
    "plt.suptitle('Sentiment analysis on Reply tweets under Catergory Rumour',fontsize=16)\n",
    "plt.title('Reply tweets show more positive attitude towards rumour tweet',fontsize=12,color='grey')\n",
    "plt.savefig('graph/ebola-essien/senti_reply_rumour.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.label ==0]['reply_sentiment'].value_counts())\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='reply_sentiment',data= df[df['label'] == 0])\n",
    "\n",
    "plt.suptitle('Sentiment analysis on Reply tweets under Catergory Non-Rumour',fontsize=16)\n",
    "plt.title('Reply tweets show more neutrual attitude towards non-rumour tweet',fontsize=12,color='grey')\n",
    "plt.savefig('graph/ebola-essien/senti_reply_nonrumour.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_tw_df['src_sentiment'].value_counts())\n",
    "sns.countplot(x='src_sentiment',data =src_tw_df,hue='label')\n",
    "\n",
    "plt.suptitle('Sentiment analysis on Source Tweets',fontsize=16)\n",
    "plt.title('Rumour source tweets show more neutral attitude.',fontsize=12,color='grey')\n",
    "plt.savefig('graph/ebola-essien/senti_source.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-domestic",
   "metadata": {},
   "source": [
    "### save data to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\ebola-essien-df.csv',index=False)\n",
    "src_tw_df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\ebola-essien-src.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-christianity",
   "metadata": {},
   "source": [
    "## Keywords Extraction\n",
    "### WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(docx)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-glucose",
   "metadata": {},
   "source": [
    "#### Reply Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_sen = df.cleaned_reply_tw.apply(word_tokenize)\n",
    "reply_tw_list = []\n",
    "for sen in reply_sen:\n",
    "    for token in sen:\n",
    "        reply_tw_list.append(token)\n",
    "reply_tw_doc = \" \".join(reply_tw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(reply_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/ebola-essien/wordcloud_reply.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive \n",
    "posi_reply_sen = df[df.reply_sentiment=='Positive'].cleaned_reply_tw.apply(word_tokenize)\n",
    "posi_reply_tw_list = []\n",
    "for sen in posi_reply_sen:\n",
    "    for token in sen:\n",
    "        posi_reply_tw_list.append(token)\n",
    "posi_reply_tw_doc = \" \".join(posi_reply_tw_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(posi_reply_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/ebola-essien/wordcloud_reply_posi.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-plenty",
   "metadata": {},
   "source": [
    "#### Source Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sen = src_tw_df.cleaned_src_tw.apply(word_tokenize)\n",
    "src_tw_list = []\n",
    "for sen in src_sen:\n",
    "    for token in sen:\n",
    "        src_tw_list.append(token)\n",
    "\n",
    "src_tw_doc = \" \".join(src_tw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(src_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/ebola-essien/wordcloud_src.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-congress",
   "metadata": {},
   "source": [
    "### Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(docx,num=30):\n",
    "    word_tokens = Counter(docx)\n",
    "    most_common = word_tokens.most_common(num)\n",
    "    result = dict(most_common)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_tokens(reply_tw_list).items(),columns=['word','freq']).plot(kind='bar',x='word',y='freq')\n",
    "plt.title(\"Most frequent words among reply tweets are 'Prince','show','tonight'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_tokens(src_tw_list).items(),columns=['word','freq']).plot(kind='bar',x='word',y='freq')\n",
    "plt.title(\"Most frequent words among source tweets are 'Price', 'show', 'tonight'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-concord",
   "metadata": {},
   "source": [
    "## Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-negotiation",
   "metadata": {},
   "source": [
    "### text2emotion package\n",
    "https://snyk.io/advisor/python/text2emotion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import text2emotion as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = df.cleaned_reply_tw.apply(te.get_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emo = emotion.apply(lambda x: max(x,key=x.get))\n",
    "df['reply_emotion']=emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\ebola-essien-df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion1 = src_tw_df.cleaned_src_tw.apply(te.get_emotion)\n",
    "# emo1 = emotion.apply(lambda x: max(x,key=x.get))\n",
    "src_tw_df['src_emotion']=emo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tw_df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\ebola-essien-src.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-ukraine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-conviction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-profession",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
