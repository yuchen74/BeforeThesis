{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prepared-posting",
   "metadata": {},
   "source": [
    "# Text Analysis on Charliehebdo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "correct-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "auburn-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\charliehebdo.csv', encoding = 'utf-8', header = None)\n",
    "df.columns = ['src_tweet_id', 'src_user_id', 'src_tweet','src_date','reply_tweet_id','reply_user_id','reply_tweet','reply_date', 'label']\n",
    "df.reply_tweet = df.reply_tweet.replace(np.nan,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convertible-librarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tweet_id</th>\n",
       "      <th>src_user_id</th>\n",
       "      <th>src_tweet</th>\n",
       "      <th>src_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552784600502915072</td>\n",
       "      <td>331658004</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>Wed Jan 07 11:11:33 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>552784898743099392</td>\n",
       "      <td>465973</td>\n",
       "      <td>Charlie Hebdo’s Last Tweet Before Shootings ht...</td>\n",
       "      <td>Wed Jan 07 11:12:44 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>552785391653494784</td>\n",
       "      <td>15798091</td>\n",
       "      <td>Prediction: the #CharlieHebdo massacre will no...</td>\n",
       "      <td>Wed Jan 07 11:14:42 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>552786116404072448</td>\n",
       "      <td>465973</td>\n",
       "      <td>10:28am Charlie Hebdo account mocks ISIS leade...</td>\n",
       "      <td>Wed Jan 07 11:17:35 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>552786299875520512</td>\n",
       "      <td>144301368</td>\n",
       "      <td>If your faith isn't strong enough to cope with...</td>\n",
       "      <td>Wed Jan 07 11:18:18 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36102</th>\n",
       "      <td>553590653784195072</td>\n",
       "      <td>380648579</td>\n",
       "      <td>#BREAKING Paris supermarket hostage-taker 'neu...</td>\n",
       "      <td>Fri Jan 09 16:34:31 +0000 2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36123</th>\n",
       "      <td>553590721207615488</td>\n",
       "      <td>5402612</td>\n",
       "      <td>Hostages held at kosher supermarket in eastern...</td>\n",
       "      <td>Fri Jan 09 16:34:47 +0000 2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36146</th>\n",
       "      <td>553590835850514433</td>\n",
       "      <td>7587032</td>\n",
       "      <td>Hostage-taker in supermarket siege killed, rep...</td>\n",
       "      <td>Fri Jan 09 16:35:15 +0000 2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36166</th>\n",
       "      <td>553590891852886019</td>\n",
       "      <td>18424289</td>\n",
       "      <td>French media reports two suspects of #CharlieH...</td>\n",
       "      <td>Fri Jan 09 16:35:28 +0000 2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36169</th>\n",
       "      <td>553591259672379392</td>\n",
       "      <td>87416722</td>\n",
       "      <td>Update - PA: gunman holding hostages in #Paris...</td>\n",
       "      <td>Fri Jan 09 16:36:56 +0000 2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2002 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             src_tweet_id  src_user_id  \\\n",
       "0      552784600502915072    331658004   \n",
       "39     552784898743099392       465973   \n",
       "48     552785391653494784     15798091   \n",
       "79     552786116404072448       465973   \n",
       "84     552786299875520512    144301368   \n",
       "...                   ...          ...   \n",
       "36102  553590653784195072    380648579   \n",
       "36123  553590721207615488      5402612   \n",
       "36146  553590835850514433      7587032   \n",
       "36166  553590891852886019     18424289   \n",
       "36169  553591259672379392     87416722   \n",
       "\n",
       "                                               src_tweet  \\\n",
       "0      Charlie Hebdo became well known for publishing...   \n",
       "39     Charlie Hebdo’s Last Tweet Before Shootings ht...   \n",
       "48     Prediction: the #CharlieHebdo massacre will no...   \n",
       "79     10:28am Charlie Hebdo account mocks ISIS leade...   \n",
       "84     If your faith isn't strong enough to cope with...   \n",
       "...                                                  ...   \n",
       "36102  #BREAKING Paris supermarket hostage-taker 'neu...   \n",
       "36123  Hostages held at kosher supermarket in eastern...   \n",
       "36146  Hostage-taker in supermarket siege killed, rep...   \n",
       "36166  French media reports two suspects of #CharlieH...   \n",
       "36169  Update - PA: gunman holding hostages in #Paris...   \n",
       "\n",
       "                             src_date  label  \n",
       "0      Wed Jan 07 11:11:33 +0000 2015      0  \n",
       "39     Wed Jan 07 11:12:44 +0000 2015      0  \n",
       "48     Wed Jan 07 11:14:42 +0000 2015      0  \n",
       "79     Wed Jan 07 11:17:35 +0000 2015      0  \n",
       "84     Wed Jan 07 11:18:18 +0000 2015      0  \n",
       "...                               ...    ...  \n",
       "36102  Fri Jan 09 16:34:31 +0000 2015      1  \n",
       "36123  Fri Jan 09 16:34:47 +0000 2015      1  \n",
       "36146  Fri Jan 09 16:35:15 +0000 2015      1  \n",
       "36166  Fri Jan 09 16:35:28 +0000 2015      1  \n",
       "36169  Fri Jan 09 16:36:56 +0000 2015      1  \n",
       "\n",
       "[2002 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tw_df = df.iloc[:,[0,1,2,3,8]].copy()\n",
    "src_tw_df = src_tw_df.drop_duplicates()\n",
    "src_tw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-radio",
   "metadata": {},
   "source": [
    "## Prepocessing\n",
    "- Define function to process text at one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acting-collectible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textprocessing(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    text = \" \".join([word for word in text.split() if 'http' not in word\n",
    "                                and not word.startswith('@')])\n",
    "                                #and word != 'RT'])\n",
    "    import re\n",
    "    def remove_punct(tweet):\n",
    "        new_words = []\n",
    "        for word in tweet:\n",
    "            w = re.sub(r'[^\\w\\s]','',word) #remove everything except words and space\n",
    "            w = re.sub(r'_','',w) #how to remove underscore as well\n",
    "            new_words.append(w)\n",
    "\n",
    "        return new_words\n",
    "    text = \"\".join(remove_punct(text))\n",
    "          \n",
    "    from nltk.tokenize import TweetTokenizer\n",
    "    tknzr = TweetTokenizer(strip_handles=True)\n",
    "    text = tknzr.tokenize(text)\n",
    "    \n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stem = PorterStemmer()\n",
    "    text = [stem.stem(i) for i in text]\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    def filterstopwords(tw):\n",
    "        filter_stopwords = []\n",
    "        for w in tw:\n",
    "            if w not in stop_words:\n",
    "                filter_stopwords.append(w)\n",
    "        return filter_stopwords\n",
    "    text = filterstopwords(text)\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greenhouse-review",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:  @lj_kulwicki @GabTarquini @BBCDanielS @BBCWorld We're not allowed to commit heinous crimes, especially in the name of God.\n",
      "cleaned text:  allow commit heinou crime especi name god\n"
     ]
    }
   ],
   "source": [
    "print(\"original text: \", df.reply_tweet.iloc[20])\n",
    "print(\"cleaned text: \", textprocessing(df.reply_tweet.iloc[20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-figure",
   "metadata": {},
   "source": [
    "### applied on original data (**df**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "substantial-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_src_tw'] = df.src_tweet.apply(textprocessing)\n",
    "df['cleaned_reply_tw'] = df.reply_tweet.apply(textprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interior-dallas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tweet_id</th>\n",
       "      <th>src_user_id</th>\n",
       "      <th>src_tweet</th>\n",
       "      <th>src_date</th>\n",
       "      <th>reply_tweet_id</th>\n",
       "      <th>reply_user_id</th>\n",
       "      <th>reply_tweet</th>\n",
       "      <th>reply_date</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_src_tw</th>\n",
       "      <th>cleaned_reply_tw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552784600502915072</td>\n",
       "      <td>331658004</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>Wed Jan 07 11:11:33 +0000 2015</td>\n",
       "      <td>552785249420447745</td>\n",
       "      <td>18370911</td>\n",
       "      <td>Now 10 dead in a shooting there today RT \"@BBC...</td>\n",
       "      <td>Wed Jan 07 11:14:08 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>charli hebdo becam well known publish muham ca...</td>\n",
       "      <td>10 dead shoot today rt bbcdaniel charli hebdo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552784600502915072</td>\n",
       "      <td>331658004</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>Wed Jan 07 11:11:33 +0000 2015</td>\n",
       "      <td>552786761534144512</td>\n",
       "      <td>2806109387</td>\n",
       "      <td>@BBCDanielS @BBCWorld I'm guessing this is bei...</td>\n",
       "      <td>Wed Jan 07 11:20:08 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>charli hebdo becam well known publish muham ca...</td>\n",
       "      <td>im guess thi consid terror right lone wolf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552784600502915072</td>\n",
       "      <td>331658004</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>Wed Jan 07 11:11:33 +0000 2015</td>\n",
       "      <td>552786803884060672</td>\n",
       "      <td>146142164</td>\n",
       "      <td>@BBCDanielS @BBCWorld why would you mention th...</td>\n",
       "      <td>Wed Jan 07 11:20:18 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>charli hebdo becam well known publish muham ca...</td>\n",
       "      <td>whi would mention befor know fact islamphobiaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552784600502915072</td>\n",
       "      <td>331658004</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>Wed Jan 07 11:11:33 +0000 2015</td>\n",
       "      <td>552786954656710656</td>\n",
       "      <td>940853760</td>\n",
       "      <td>@BBCDanielS @BBCWorld perps identified?</td>\n",
       "      <td>Wed Jan 07 11:20:54 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>charli hebdo becam well known publish muham ca...</td>\n",
       "      <td>perp identifi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552784600502915072</td>\n",
       "      <td>331658004</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>Wed Jan 07 11:11:33 +0000 2015</td>\n",
       "      <td>552787979224092672</td>\n",
       "      <td>2888783532</td>\n",
       "      <td>@BBCDanielS @BBCWorld who is charlie hebdo?</td>\n",
       "      <td>Wed Jan 07 11:24:59 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>charli hebdo becam well known publish muham ca...</td>\n",
       "      <td>charli hebdo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         src_tweet_id  src_user_id  \\\n",
       "0  552784600502915072    331658004   \n",
       "1  552784600502915072    331658004   \n",
       "2  552784600502915072    331658004   \n",
       "3  552784600502915072    331658004   \n",
       "4  552784600502915072    331658004   \n",
       "\n",
       "                                           src_tweet  \\\n",
       "0  Charlie Hebdo became well known for publishing...   \n",
       "1  Charlie Hebdo became well known for publishing...   \n",
       "2  Charlie Hebdo became well known for publishing...   \n",
       "3  Charlie Hebdo became well known for publishing...   \n",
       "4  Charlie Hebdo became well known for publishing...   \n",
       "\n",
       "                         src_date      reply_tweet_id  reply_user_id  \\\n",
       "0  Wed Jan 07 11:11:33 +0000 2015  552785249420447745       18370911   \n",
       "1  Wed Jan 07 11:11:33 +0000 2015  552786761534144512     2806109387   \n",
       "2  Wed Jan 07 11:11:33 +0000 2015  552786803884060672      146142164   \n",
       "3  Wed Jan 07 11:11:33 +0000 2015  552786954656710656      940853760   \n",
       "4  Wed Jan 07 11:11:33 +0000 2015  552787979224092672     2888783532   \n",
       "\n",
       "                                         reply_tweet  \\\n",
       "0  Now 10 dead in a shooting there today RT \"@BBC...   \n",
       "1  @BBCDanielS @BBCWorld I'm guessing this is bei...   \n",
       "2  @BBCDanielS @BBCWorld why would you mention th...   \n",
       "3            @BBCDanielS @BBCWorld perps identified?   \n",
       "4        @BBCDanielS @BBCWorld who is charlie hebdo?   \n",
       "\n",
       "                       reply_date  label  \\\n",
       "0  Wed Jan 07 11:14:08 +0000 2015      0   \n",
       "1  Wed Jan 07 11:20:08 +0000 2015      0   \n",
       "2  Wed Jan 07 11:20:18 +0000 2015      0   \n",
       "3  Wed Jan 07 11:20:54 +0000 2015      0   \n",
       "4  Wed Jan 07 11:24:59 +0000 2015      0   \n",
       "\n",
       "                                      cleaned_src_tw  \\\n",
       "0  charli hebdo becam well known publish muham ca...   \n",
       "1  charli hebdo becam well known publish muham ca...   \n",
       "2  charli hebdo becam well known publish muham ca...   \n",
       "3  charli hebdo becam well known publish muham ca...   \n",
       "4  charli hebdo becam well known publish muham ca...   \n",
       "\n",
       "                                    cleaned_reply_tw  \n",
       "0  10 dead shoot today rt bbcdaniel charli hebdo ...  \n",
       "1         im guess thi consid terror right lone wolf  \n",
       "2  whi would mention befor know fact islamphobiaa...  \n",
       "3                                      perp identifi  \n",
       "4                                       charli hebdo  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-empire",
   "metadata": {},
   "source": [
    "### applied on source tweet data (**src_tw_df**) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "criminal-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tw_df['cleaned_src_tw'] = src_tw_df.src_tweet.apply(textprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-nirvana",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "owned-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "living-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tweet):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    if vs['compound'] >=0.05:\n",
    "        sentiment_label = 'Positive'\n",
    "    elif (vs['compound'] > -0.05) & (vs['compound'] < 0.05):\n",
    "        sentiment_label = 'Neutral'\n",
    "    elif vs['compound']<= -0.05:\n",
    "        sentiment_label = 'Negative' \n",
    "    result = sentiment_label\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-guarantee",
   "metadata": {},
   "source": [
    "### applied on original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "false-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['src_sentiment']= df.cleaned_src_tw.apply(get_sentiment)\n",
    "df['reply_sentiment']= df.cleaned_reply_tw.apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adjusted-victor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tweet_id</th>\n",
       "      <th>src_user_id</th>\n",
       "      <th>src_tweet</th>\n",
       "      <th>src_date</th>\n",
       "      <th>reply_tweet_id</th>\n",
       "      <th>reply_user_id</th>\n",
       "      <th>reply_tweet</th>\n",
       "      <th>reply_date</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_src_tw</th>\n",
       "      <th>cleaned_reply_tw</th>\n",
       "      <th>src_sentiment</th>\n",
       "      <th>reply_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552784600502915072</td>\n",
       "      <td>331658004</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>Wed Jan 07 11:11:33 +0000 2015</td>\n",
       "      <td>552785249420447745</td>\n",
       "      <td>18370911</td>\n",
       "      <td>Now 10 dead in a shooting there today RT \"@BBC...</td>\n",
       "      <td>Wed Jan 07 11:14:08 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>charli hebdo becam well known publish muham ca...</td>\n",
       "      <td>10 dead shoot today rt bbcdaniel charli hebdo ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         src_tweet_id  src_user_id  \\\n",
       "0  552784600502915072    331658004   \n",
       "\n",
       "                                           src_tweet  \\\n",
       "0  Charlie Hebdo became well known for publishing...   \n",
       "\n",
       "                         src_date      reply_tweet_id  reply_user_id  \\\n",
       "0  Wed Jan 07 11:11:33 +0000 2015  552785249420447745       18370911   \n",
       "\n",
       "                                         reply_tweet  \\\n",
       "0  Now 10 dead in a shooting there today RT \"@BBC...   \n",
       "\n",
       "                       reply_date  label  \\\n",
       "0  Wed Jan 07 11:14:08 +0000 2015      0   \n",
       "\n",
       "                                      cleaned_src_tw  \\\n",
       "0  charli hebdo becam well known publish muham ca...   \n",
       "\n",
       "                                    cleaned_reply_tw src_sentiment  \\\n",
       "0  10 dead shoot today rt bbcdaniel charli hebdo ...      Positive   \n",
       "\n",
       "  reply_sentiment  \n",
       "0        Negative  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-disposal",
   "metadata": {},
   "source": [
    "### applied on source tweet data only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "effective-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "### source tweet data only \n",
    "src_tw_df['src_sentiment']=  src_tw_df['cleaned_src_tw'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-surrey",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.label ==1]['reply_sentiment'].value_counts())\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='reply_sentiment',data= df[df['label'] == 1])\n",
    "\n",
    "plt.suptitle('Sentiment analysis on Reply tweets under Catergory Rumour',fontsize=16)\n",
    "plt.title('Reply tweets show more positive attitude towards rumour tweet',fontsize=12,color='grey')\n",
    "plt.savefig('graph/charliehebdo/senti_reply_rumour.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.label ==0]['reply_sentiment'].value_counts())\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='reply_sentiment',data= df[df['label'] == 0])\n",
    "\n",
    "plt.suptitle('Sentiment analysis on Reply tweets under Catergory Non-Rumour',fontsize=16)\n",
    "plt.title('Reply tweets show more neutrual attitude towards non-rumour tweet',fontsize=12,color='grey')\n",
    "plt.savefig('graph/charliehebdo/senti_reply_nonrumour.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_tw_df['src_sentiment'].value_counts())\n",
    "sns.countplot(x='src_sentiment',data =src_tw_df,hue='label')\n",
    "\n",
    "plt.suptitle('Sentiment analysis on Source Tweets',fontsize=16)\n",
    "plt.title('Rumour source tweets show more neutral attitude.',fontsize=12,color='grey')\n",
    "plt.savefig('graph/charliehebdo/senti_source.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-circle",
   "metadata": {},
   "source": [
    "### save data to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\charliehebdo-df.csv',index=False)\n",
    "src_tw_df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\charliehebdo-src.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-burner",
   "metadata": {},
   "source": [
    "## Keywords Extraction\n",
    "### WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(docx)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-biodiversity",
   "metadata": {},
   "source": [
    "#### Reply Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_sen = df.cleaned_reply_tw.apply(word_tokenize)\n",
    "reply_tw_list = []\n",
    "for sen in reply_sen:\n",
    "    for token in sen:\n",
    "        reply_tw_list.append(token)\n",
    "reply_tw_doc = \" \".join(reply_tw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(reply_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/charliehebdo/wordcloud_reply.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive \n",
    "posi_reply_sen = df[df.reply_sentiment=='Positive'].cleaned_reply_tw.apply(word_tokenize)\n",
    "posi_reply_tw_list = []\n",
    "for sen in posi_reply_sen:\n",
    "    for token in sen:\n",
    "        posi_reply_tw_list.append(token)\n",
    "posi_reply_tw_doc = \" \".join(posi_reply_tw_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(posi_reply_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/charliehebdo/wordcloud_reply_posi.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-fitting",
   "metadata": {},
   "source": [
    "#### Source Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sen = src_tw_df.cleaned_src_tw.apply(word_tokenize)\n",
    "src_tw_list = []\n",
    "for sen in src_sen:\n",
    "    for token in sen:\n",
    "        src_tw_list.append(token)\n",
    "\n",
    "src_tw_doc = \" \".join(src_tw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(src_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/charliehebdo/wordcloud_src.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-gospel",
   "metadata": {},
   "source": [
    "### Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "freq = FreqDist(processed_text)\n",
    "freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(docx,num=30):\n",
    "    word_tokens = Counter(docx)\n",
    "    most_common = word_tokens.most_common(num)\n",
    "    result = dict(most_common)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_tokens(reply_tw_list).items(),columns=['word','freq']).plot(kind='bar',x='word',y='freq')\n",
    "plt.title(\"Most frequent words among reply tweets are 'Prince','show','tonight'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_tokens(src_tw_list).items(),columns=['word','freq']).plot(kind='bar',x='word',y='freq')\n",
    "plt.title(\"Most frequent words among source tweets are 'Price', 'show', 'tonight'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-aspect",
   "metadata": {},
   "source": [
    "## Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-carpet",
   "metadata": {},
   "source": [
    "### text2emotion package\n",
    "https://snyk.io/advisor/python/text2emotion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "basic-least",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import text2emotion as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "generic-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = df.cleaned_reply_tw.apply(te.get_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "outstanding-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo = emotion.apply(lambda x: max(x,key=x.get))\n",
    "df['reply_emotion'] = emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "speaking-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\charliehebdo-df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "quantitative-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion1 = src_tw_df.cleaned_src_tw.apply(te.get_emotion)\n",
    "emo1 = emotion.apply(lambda x: max(x,key=x.get))\n",
    "src_tw_df['src_emotion']=emo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cooked-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tw_df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\charliehebdo-src.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "digital-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tw_df.drop('emotion',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-gasoline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
