{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regional-nancy",
   "metadata": {},
   "source": [
    "# Text Analysis on prince-toronto data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "considerable-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "incredible-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\prince-toronto.csv', encoding = 'utf-8', header = None)\n",
    "df.columns = ['src_tweet_id', 'src_user_id', 'src_tweet','src_date','reply_tweet_id','reply_user_id','reply_tweet','reply_date', 'label']\n",
    "df.reply_tweet = df.reply_tweet.replace(np.nan,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "printable-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tweet_id</th>\n",
       "      <th>src_user_id</th>\n",
       "      <th>src_tweet</th>\n",
       "      <th>src_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>529590949136326656</td>\n",
       "      <td>842564341</td>\n",
       "      <td>As an aside, Toronto is home to @magpietoronto...</td>\n",
       "      <td>Tue Nov 04 11:08:16 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>529695075560071168</td>\n",
       "      <td>134586361</td>\n",
       "      <td>Prince loves this city. He fell for the Toront...</td>\n",
       "      <td>Tue Nov 04 18:02:01 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>529755373721632768</td>\n",
       "      <td>1395136699</td>\n",
       "      <td>PRINCE gives Toronto purple balls .....</td>\n",
       "      <td>Tue Nov 04 22:01:38 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>529761572881985536</td>\n",
       "      <td>43451286</td>\n",
       "      <td>Dammit Prince. Toronto needs a win right now.</td>\n",
       "      <td>Tue Nov 04 22:26:16 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>529399936434327552</td>\n",
       "      <td>23607802</td>\n",
       "      <td>can someone get us in 2 the secret prince show...</td>\n",
       "      <td>Mon Nov 03 22:29:15 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>529778109290012673</td>\n",
       "      <td>102611790</td>\n",
       "      <td>this nigga Prince got all the unemployed middl...</td>\n",
       "      <td>Tue Nov 04 23:31:58 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>529818929607475201</td>\n",
       "      <td>21137035</td>\n",
       "      <td>Live Nation wants to apologize for any inconve...</td>\n",
       "      <td>Wed Nov 05 02:14:11 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>529828486975066112</td>\n",
       "      <td>20247647</td>\n",
       "      <td>#Toronto - sorry for the confusion today surro...</td>\n",
       "      <td>Wed Nov 05 02:52:09 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>529830319982407680</td>\n",
       "      <td>526528241</td>\n",
       "      <td>From @DonnaGrantis on Facebook. @3RDEYEGIRL #T...</td>\n",
       "      <td>Wed Nov 05 02:59:26 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>529830606210093058</td>\n",
       "      <td>291792912</td>\n",
       "      <td>PRINCE in Toronto details. Just a production r...</td>\n",
       "      <td>Wed Nov 05 03:00:34 +0000 2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           src_tweet_id  src_user_id  \\\n",
       "0    529590949136326656    842564341   \n",
       "1    529695075560071168    134586361   \n",
       "3    529755373721632768   1395136699   \n",
       "4    529761572881985536     43451286   \n",
       "5    529399936434327552     23607802   \n",
       "..                  ...          ...   \n",
       "743  529778109290012673    102611790   \n",
       "744  529818929607475201     21137035   \n",
       "757  529828486975066112     20247647   \n",
       "763  529830319982407680    526528241   \n",
       "764  529830606210093058    291792912   \n",
       "\n",
       "                                             src_tweet  \\\n",
       "0    As an aside, Toronto is home to @magpietoronto...   \n",
       "1    Prince loves this city. He fell for the Toront...   \n",
       "3              PRINCE gives Toronto purple balls .....   \n",
       "4        Dammit Prince. Toronto needs a win right now.   \n",
       "5    can someone get us in 2 the secret prince show...   \n",
       "..                                                 ...   \n",
       "743  this nigga Prince got all the unemployed middl...   \n",
       "744  Live Nation wants to apologize for any inconve...   \n",
       "757  #Toronto - sorry for the confusion today surro...   \n",
       "763  From @DonnaGrantis on Facebook. @3RDEYEGIRL #T...   \n",
       "764  PRINCE in Toronto details. Just a production r...   \n",
       "\n",
       "                           src_date  label  \n",
       "0    Tue Nov 04 11:08:16 +0000 2014      0  \n",
       "1    Tue Nov 04 18:02:01 +0000 2014      0  \n",
       "3    Tue Nov 04 22:01:38 +0000 2014      0  \n",
       "4    Tue Nov 04 22:26:16 +0000 2014      0  \n",
       "5    Mon Nov 03 22:29:15 +0000 2014      1  \n",
       "..                              ...    ...  \n",
       "743  Tue Nov 04 23:31:58 +0000 2014      1  \n",
       "744  Wed Nov 05 02:14:11 +0000 2014      1  \n",
       "757  Wed Nov 05 02:52:09 +0000 2014      1  \n",
       "763  Wed Nov 05 02:59:26 +0000 2014      1  \n",
       "764  Wed Nov 05 03:00:34 +0000 2014      1  \n",
       "\n",
       "[233 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tw_df = df.iloc[:,[0,1,2,3,8]].copy()\n",
    "src_tw_df = src_tw_df.drop_duplicates()\n",
    "src_tw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-minnesota",
   "metadata": {},
   "source": [
    "## Prepocessing\n",
    "- Define function to process text at one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "connected-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textprocessing(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    text = \" \".join([word for word in text.split() if 'http' not in word\n",
    "                                and not word.startswith('@')])\n",
    "                                #and word != 'RT'])\n",
    "    import re\n",
    "    def remove_punct(tweet):\n",
    "        new_words = []\n",
    "        for word in tweet:\n",
    "            w = re.sub(r'[^\\w\\s]','',word) #remove everything except words and space\n",
    "            w = re.sub(r'_','',w) #how to remove underscore as well\n",
    "            new_words.append(w)\n",
    "\n",
    "        return new_words\n",
    "    text = \"\".join(remove_punct(text))\n",
    "          \n",
    "    from nltk.tokenize import TweetTokenizer\n",
    "    tknzr = TweetTokenizer(strip_handles=True)\n",
    "    text = tknzr.tokenize(text)\n",
    "    \n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stem = PorterStemmer()\n",
    "    text = [stem.stem(i) for i in text]\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words=set(stopwords.words(\"english\"))\n",
    "    def filterstopwords(tw):\n",
    "        filter_stopwords = []\n",
    "        for w in tw:\n",
    "            if w not in stop_words:\n",
    "                filter_stopwords.append(w)\n",
    "        return filter_stopwords\n",
    "    text = filterstopwords(text)\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "north-vertex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:  @FOHPhoto @AUXTV I need to hear chocolate rain live....\n",
      "cleaned text:  need hear chocol rain live\n"
     ]
    }
   ],
   "source": [
    "print(\"original text: \", df.reply_tweet.iloc[20])\n",
    "print(\"cleaned text: \", textprocessing(df.reply_tweet.iloc[20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-naples",
   "metadata": {},
   "source": [
    "### applied on original data (**df**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "surgical-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_src_tw'] = df.src_tweet.apply(textprocessing)\n",
    "df['cleaned_reply_tw'] = df.reply_tweet.apply(textprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "inner-nicaragua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tweet_id</th>\n",
       "      <th>src_user_id</th>\n",
       "      <th>src_tweet</th>\n",
       "      <th>src_date</th>\n",
       "      <th>reply_tweet_id</th>\n",
       "      <th>reply_user_id</th>\n",
       "      <th>reply_tweet</th>\n",
       "      <th>reply_date</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_src_tw</th>\n",
       "      <th>cleaned_reply_tw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>529590949136326656</td>\n",
       "      <td>842564341</td>\n",
       "      <td>As an aside, Toronto is home to @magpietoronto...</td>\n",
       "      <td>Tue Nov 04 11:08:16 +0000 2014</td>\n",
       "      <td>5.295916e+17</td>\n",
       "      <td>1.538385e+09</td>\n",
       "      <td>@PrinceMuseum @magpietoronto @3RDEYEGIRL Lol, ...</td>\n",
       "      <td>Tue Nov 04 11:11:03 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>asid toronto home princ get lot stage cloth</td>\n",
       "      <td>lol hope stock summer rang 2 pop 2 australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>529695075560071168</td>\n",
       "      <td>134586361</td>\n",
       "      <td>Prince loves this city. He fell for the Toront...</td>\n",
       "      <td>Tue Nov 04 18:02:01 +0000 2014</td>\n",
       "      <td>5.296965e+17</td>\n",
       "      <td>6.211173e+07</td>\n",
       "      <td>“@ellhah: Prince loves this city. He fell for ...</td>\n",
       "      <td>Tue Nov 04 18:07:49 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>princ love thi citi fell toronto woman trap ha...</td>\n",
       "      <td>ellhah princ love thi citi fell toronto woman ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>529695075560071168</td>\n",
       "      <td>134586361</td>\n",
       "      <td>Prince loves this city. He fell for the Toront...</td>\n",
       "      <td>Tue Nov 04 18:02:01 +0000 2014</td>\n",
       "      <td>5.296980e+17</td>\n",
       "      <td>4.464473e+07</td>\n",
       "      <td>@ellhah Prince x Red Drink Boutique invite onl...</td>\n",
       "      <td>Tue Nov 04 18:13:30 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>princ love thi citi fell toronto woman trap ha...</td>\n",
       "      <td>princ x red drink boutiqu invit onli parti sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>529755373721632768</td>\n",
       "      <td>1395136699</td>\n",
       "      <td>PRINCE gives Toronto purple balls .....</td>\n",
       "      <td>Tue Nov 04 22:01:38 +0000 2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>princ give toronto purpl ball</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>529761572881985536</td>\n",
       "      <td>43451286</td>\n",
       "      <td>Dammit Prince. Toronto needs a win right now.</td>\n",
       "      <td>Tue Nov 04 22:26:16 +0000 2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>dammit princ toronto need win right</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         src_tweet_id  src_user_id  \\\n",
       "0  529590949136326656    842564341   \n",
       "1  529695075560071168    134586361   \n",
       "2  529695075560071168    134586361   \n",
       "3  529755373721632768   1395136699   \n",
       "4  529761572881985536     43451286   \n",
       "\n",
       "                                           src_tweet  \\\n",
       "0  As an aside, Toronto is home to @magpietoronto...   \n",
       "1  Prince loves this city. He fell for the Toront...   \n",
       "2  Prince loves this city. He fell for the Toront...   \n",
       "3            PRINCE gives Toronto purple balls .....   \n",
       "4      Dammit Prince. Toronto needs a win right now.   \n",
       "\n",
       "                         src_date  reply_tweet_id  reply_user_id  \\\n",
       "0  Tue Nov 04 11:08:16 +0000 2014    5.295916e+17   1.538385e+09   \n",
       "1  Tue Nov 04 18:02:01 +0000 2014    5.296965e+17   6.211173e+07   \n",
       "2  Tue Nov 04 18:02:01 +0000 2014    5.296980e+17   4.464473e+07   \n",
       "3  Tue Nov 04 22:01:38 +0000 2014             NaN            NaN   \n",
       "4  Tue Nov 04 22:26:16 +0000 2014             NaN            NaN   \n",
       "\n",
       "                                         reply_tweet  \\\n",
       "0  @PrinceMuseum @magpietoronto @3RDEYEGIRL Lol, ...   \n",
       "1  “@ellhah: Prince loves this city. He fell for ...   \n",
       "2  @ellhah Prince x Red Drink Boutique invite onl...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                       reply_date  label  \\\n",
       "0  Tue Nov 04 11:11:03 +0000 2014      0   \n",
       "1  Tue Nov 04 18:07:49 +0000 2014      0   \n",
       "2  Tue Nov 04 18:13:30 +0000 2014      0   \n",
       "3                             NaN      0   \n",
       "4                             NaN      0   \n",
       "\n",
       "                                      cleaned_src_tw  \\\n",
       "0        asid toronto home princ get lot stage cloth   \n",
       "1  princ love thi citi fell toronto woman trap ha...   \n",
       "2  princ love thi citi fell toronto woman trap ha...   \n",
       "3                      princ give toronto purpl ball   \n",
       "4                dammit princ toronto need win right   \n",
       "\n",
       "                                    cleaned_reply_tw  \n",
       "0       lol hope stock summer rang 2 pop 2 australia  \n",
       "1  ellhah princ love thi citi fell toronto woman ...  \n",
       "2  princ x red drink boutiqu invit onli parti sto...  \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-poland",
   "metadata": {},
   "source": [
    "### applied on source tweet data (**src_tw_df**) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "uniform-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tw_df['cleaned_src_tw'] = src_tw_df.src_tweet.apply(textprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-irrigation",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fresh-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "streaming-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tweet):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    if vs['compound'] >=0.05:\n",
    "        sentiment_label = 'Positive'\n",
    "    elif (vs['compound'] > -0.05) & (vs['compound'] < 0.05):\n",
    "        sentiment_label = 'Neutral'\n",
    "    elif vs['compound']<= -0.05:\n",
    "        sentiment_label = 'Negative' \n",
    "    result = sentiment_label\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-creativity",
   "metadata": {},
   "source": [
    "### applied on original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "center-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['src_sentiment']= df.cleaned_src_tw.apply(get_sentiment)\n",
    "df['reply_sentiment']= df.cleaned_reply_tw.apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "invalid-harvey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_tweet_id</th>\n",
       "      <th>src_user_id</th>\n",
       "      <th>src_tweet</th>\n",
       "      <th>src_date</th>\n",
       "      <th>reply_tweet_id</th>\n",
       "      <th>reply_user_id</th>\n",
       "      <th>reply_tweet</th>\n",
       "      <th>reply_date</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_src_tw</th>\n",
       "      <th>cleaned_reply_tw</th>\n",
       "      <th>src_sentiment</th>\n",
       "      <th>reply_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>529590949136326656</td>\n",
       "      <td>842564341</td>\n",
       "      <td>As an aside, Toronto is home to @magpietoronto...</td>\n",
       "      <td>Tue Nov 04 11:08:16 +0000 2014</td>\n",
       "      <td>5.295916e+17</td>\n",
       "      <td>1.538385e+09</td>\n",
       "      <td>@PrinceMuseum @magpietoronto @3RDEYEGIRL Lol, ...</td>\n",
       "      <td>Tue Nov 04 11:11:03 +0000 2014</td>\n",
       "      <td>0</td>\n",
       "      <td>asid toronto home princ get lot stage cloth</td>\n",
       "      <td>lol hope stock summer rang 2 pop 2 australia</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         src_tweet_id  src_user_id  \\\n",
       "0  529590949136326656    842564341   \n",
       "\n",
       "                                           src_tweet  \\\n",
       "0  As an aside, Toronto is home to @magpietoronto...   \n",
       "\n",
       "                         src_date  reply_tweet_id  reply_user_id  \\\n",
       "0  Tue Nov 04 11:08:16 +0000 2014    5.295916e+17   1.538385e+09   \n",
       "\n",
       "                                         reply_tweet  \\\n",
       "0  @PrinceMuseum @magpietoronto @3RDEYEGIRL Lol, ...   \n",
       "\n",
       "                       reply_date  label  \\\n",
       "0  Tue Nov 04 11:11:03 +0000 2014      0   \n",
       "\n",
       "                                cleaned_src_tw  \\\n",
       "0  asid toronto home princ get lot stage cloth   \n",
       "\n",
       "                               cleaned_reply_tw src_sentiment reply_sentiment  \n",
       "0  lol hope stock summer rang 2 pop 2 australia       Neutral        Positive  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-private",
   "metadata": {},
   "source": [
    "### applied on source tweet data only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "reasonable-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "### source tweet data only \n",
    "src_tw_df['src_sentiment']=  src_tw_df['cleaned_src_tw'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-stack",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.label ==1]['reply_sentiment'].value_counts())\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='reply_sentiment',data= df[df['label'] == 1])\n",
    "\n",
    "plt.suptitle('Sentiment analysis on Reply tweets under Catergory Rumour',fontsize=16)\n",
    "plt.title('Reply tweets show more positive attitude towards rumour tweet',fontsize=12,color='grey')\n",
    "plt.savefig('graph/prince-toronto/senti_reply_rumour.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.label ==0]['reply_sentiment'].value_counts())\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='reply_sentiment',data= df[df['label'] == 0])\n",
    "\n",
    "plt.suptitle('Sentiment analysis on Reply tweets under Catergory Non-Rumour',fontsize=16)\n",
    "plt.title('Reply tweets show more neutrual attitude towards non-rumour tweet',fontsize=12,color='grey')\n",
    "plt.savefig('graph/prince-toronto/senti_reply_nonrumour.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(src_tw_df['src_sentiment'].value_counts())\n",
    "sns.countplot(x='src_sentiment',data =src_tw_df,hue='label')\n",
    "\n",
    "plt.suptitle('Sentiment analysis on Source Tweets',fontsize=16)\n",
    "plt.title('Rumour source tweets show more neutral attitude.',fontsize=12,color='grey')\n",
    "plt.savefig('graph/prince-toronto/senti_source.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-encounter",
   "metadata": {},
   "source": [
    "### save data to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\prince-toronto-df.csv',index=False)\n",
    "src_tw_df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\prince-toronto-src.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-hunger",
   "metadata": {},
   "source": [
    "## Keywords Extraction\n",
    "### WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(docx)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-capacity",
   "metadata": {},
   "source": [
    "#### Reply Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_sen = df.cleaned_reply_tw.apply(word_tokenize)\n",
    "reply_tw_list = []\n",
    "for sen in reply_sen:\n",
    "    for token in sen:\n",
    "        reply_tw_list.append(token)\n",
    "reply_tw_doc = \" \".join(reply_tw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(reply_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/prince-toronto/wordcloud_reply.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive \n",
    "posi_reply_sen = df[df.reply_sentiment=='Positive'].cleaned_reply_tw.apply(word_tokenize)\n",
    "posi_reply_tw_list = []\n",
    "for sen in posi_reply_sen:\n",
    "    for token in sen:\n",
    "        posi_reply_tw_list.append(token)\n",
    "posi_reply_tw_doc = \" \".join(posi_reply_tw_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(posi_reply_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/prince-toronto/wordcloud_reply_posi.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-interpretation",
   "metadata": {},
   "source": [
    "#### Source Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sen = src_tw_df.cleaned_src_tw.apply(word_tokenize)\n",
    "src_tw_list = []\n",
    "for sen in src_sen:\n",
    "    for token in sen:\n",
    "        src_tw_list.append(token)\n",
    "\n",
    "src_tw_doc = \" \".join(src_tw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "mywordcloud = WordCloud().generate(src_tw_doc)\n",
    "plt.imshow(mywordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "mywordcloud.to_file('graph/prince-toronto/wordcloud_src.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-breed",
   "metadata": {},
   "source": [
    "### Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(docx,num=30):\n",
    "    word_tokens = Counter(docx)\n",
    "    most_common = word_tokens.most_common(num)\n",
    "    result = dict(most_common)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_tokens(reply_tw_list).items(),columns=['word','freq']).plot(kind='bar',x='word',y='freq')\n",
    "plt.title(\"Most frequent words among reply tweets are 'Prince','show','tonight'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_tokens(src_tw_list).items(),columns=['word','freq']).plot(kind='bar',x='word',y='freq')\n",
    "plt.title(\"Most frequent words among source tweets are 'Price', 'show', 'tonight'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-bibliography",
   "metadata": {},
   "source": [
    "## Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-peter",
   "metadata": {},
   "source": [
    "### text2emotion package\n",
    "https://snyk.io/advisor/python/text2emotion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "vital-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import text2emotion as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "phantom-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = df.cleaned_reply_tw.apply(te.get_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "discrete-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "emo = emotion.apply(lambda x: max(x,key=x.get))\n",
    "df['reply_emotion']=emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acknowledged-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\prince-toronto-df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "separate-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion1 = src_tw_df.cleaned_src_tw.apply(te.get_emotion)\n",
    "emo1 = emotion.apply(lambda x: max(x,key=x.get))\n",
    "src_tw_df['src_emotion']=emo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hungry-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tw_df.to_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\prince-toronto-src.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-appliance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
